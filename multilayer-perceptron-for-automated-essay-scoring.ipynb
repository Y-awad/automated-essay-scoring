{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Automated Essay Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automated essay scoring (AES) is an NLP task that aims to predict the score of an essay based on a certain set of essay quality metrics. The score depends on the grammatical, organizational, and content features of the essays. Human raters establish rubrics and provide scores based on these criteria. However, employing human raters can pose challenges due to the large number of essays to be graded (which slows down the feedback loop) and the inconsistent grades (different raters may assign different scores to the same essay, or a rater may assign different scores to the same essay if evaluated on different days).\n",
    "\n",
    "AES systems are computer systems that simulate the scoring characteristics of human raters and address the aforementioned problems. There are several models used in AES systems. The most crucial aspect of an AES system is essay representation or encoding. Essay representation involves capturing useful features from the essays that help measure their quality. Manual feature engineering can extract features in the form of lexical, syntactic, or semantic features. This approach has been employed in industrial AES systems. However, such approaches have drawbacks in terms of generalizability and requiring feature engineering tasks.\n",
    "\n",
    "Deep learning has become a go-to approach for numerous artificial intelligence tasks, consistently achieving outstanding performance results. Deep learning eliminates the need for feature engineering as it learns automatically behind the scenes.\n",
    "\n",
    "In this project, I will demonstrate the use of deep learning for automated essay scoring tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "As it is seen in the following code snippet, I imported a number of libraries from <code>PyTorch</code>, <code>sklearn</code> and <code>python (collections)</code>. \n",
    " - <code>torch</code> is a deep learning framework that I used it for building, training and testing my models.\n",
    " - <code>torchtext</code> is sub-library in PyTorch for text data that I used it to vectorize and tokenize the essays.\n",
    " - <code>Pandas</code> is a data manipulation tool which I used it for loading the data from the disk.\n",
    " - <code>matplotlib</code> is data visualization library which I used it for generating graphs.\n",
    " - <code>numpy</code> is large and multi-dimensional arrays library which I used it for tranforming data into array.\n",
    " - <code>scikit-learn</code> is a popular machine learning library which I used it for measuring rater agreement(<code>cohen_kappa_score</code>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T06:12:43.368878Z",
     "iopub.status.busy": "2024-02-12T06:12:43.368405Z",
     "iopub.status.idle": "2024-02-12T06:12:49.825527Z",
     "shell.execute_reply": "2024-02-12T06:12:49.824146Z",
     "shell.execute_reply.started": "2024-02-12T06:12:43.368840Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model\n",
    "The following section shows the design of a multilayer perceptron model. The model has an embedding layer, 2 linear layers, 2 acitivation functions (ReLU and Sigmoid). \n",
    " - The embedding layer: <code>nn.Embedding</code> is used to capture semantic and syntactic information from the essays.\n",
    " - The linear layers: <code>nn.Linear</code> represents linear transformation. In the model, there are two linear layers. The first linear layer takes an input from the embedding layer with embedding dimension (embedding_dim) size and generate an output with hidden dimension (hidden_dim) size. The second linear layer is used to generate the score (output).\n",
    " - Activation function: <code>nn.ReLU</code> and <code>nn.Sigmoid</code> are the activation function used to transform the linear layer into nonlinear. ReLU is applied to the first linear layer whereas sigmoid is applied tothe second linear layer.\n",
    "\n",
    "This class has a constructor (<code>__init__</code>) and a forward pass (<code>forward</code>). In the constructor, the functions and the linear layers are setted. In the <code>forward</code> method, the order of computation is defined. The essay input (transformed into numbers) passed through the embedding layer. The intution here is it will capture semantic and syntactic information of the essay. And then, a mean pooling is applied. The first linear layer took the ouput of the averge pooled values and a ReLU actication function is applied over it. Finally, the second linear layer generates a value and adjusted using sigmoid activation function into a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T06:12:54.655270Z",
     "iopub.status.busy": "2024-02-12T06:12:54.654426Z",
     "iopub.status.idle": "2024-02-12T06:12:54.665931Z",
     "shell.execute_reply": "2024-02-12T06:12:54.664011Z",
     "shell.execute_reply.started": "2024-02-12T06:12:54.655226Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def normalize_scores(scores, set_id, min_scores, max_scores):\n",
    "    mi = min_scores[set_id-1]\n",
    "    ma = max_scores[set_id-1]\n",
    "    return (scores - mi) / (ma - mi)\n",
    "\n",
    "def denormalize_scores(scores_norm, set_id, min_scores, max_scores):\n",
    "    mi = min_scores[set_id-1]\n",
    "    ma = max_scores[set_id-1]\n",
    "    return scores_norm * (ma - mi) + mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EssayDataset(Dataset):\n",
    "    def __init__(self, texts, scores, tokenizer, max_len=512, embedder_name=None):\n",
    "        self.texts = texts\n",
    "        self.scores = scores\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.embedder_name = embedder_name  # keep track of which model we use\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        score = self.scores[idx]\n",
    "\n",
    "        # If using E5, prepend \"passage: \" to the essay\n",
    "        if self.embedder_name and \"e5\" in self.embedder_name.lower():\n",
    "            text = \"passage: \" + text\n",
    "\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "            \"score\": torch.tensor(score, dtype=torch.float)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset class\n",
    "I created a custom data <code>ASAPDataset</code> that takes a list of data and the vocab. This class contains three methods <code>__init__()</code>, <code>__len__()</code>, and <code>__getitem__()</code>. <code>__getitem__()</code> fetchs a sample from asap-aes dataset based on the given index. The <code>Dataset</code> provides a mechanism to load, preprocess, and iterate over the dataset.\n",
    "\n",
    "In addition, there is <code>collate_fn</code> function defined to handle padding within the essay vectors. First, the maximum token length is identified and then set all the vectors of the essays to have the same length. The padding is represented using <code>0</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T06:12:58.520593Z",
     "iopub.status.busy": "2024-02-12T06:12:58.520128Z",
     "iopub.status.idle": "2024-02-12T06:12:58.530860Z",
     "shell.execute_reply": "2024-02-12T06:12:58.529534Z",
     "shell.execute_reply.started": "2024-02-12T06:12:58.520560Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_encoder(model_name, unfreeze_last_n=0):\n",
    "    if model_name == \"roberta\":\n",
    "        name = \"roberta-base\"\n",
    "    elif model_name == \"bge\":\n",
    "        name = \"BAAI/bge-base-en\"\n",
    "    elif model_name == \"e5-base\":\n",
    "        name = \"intfloat/e5-base-v2\"\n",
    "    elif model_name == \"e5-large\":\n",
    "        name = \"intfloat/e5-large\"\n",
    "    elif model_name == \"qwen\":\n",
    "        name = \"Qwen/Qwen3-Embedding-0.6B\"   # qwen 0.6B close checkpoint\n",
    "    elif model_name == \"deberta\":\n",
    "        name = \"microsoft/deberta-v3-base\"\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(name, use_fast=True)\n",
    "    encoder = AutoModel.from_pretrained(name)\n",
    "    hidden_size = encoder.config.hidden_size\n",
    "\n",
    "    # Freeze all params\n",
    "    for param in encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Unfreeze last `unfreeze_last_n` layers if requested\n",
    "    if hasattr(encoder, \"encoder\"):  # works for RoBERTa/E5/BGE\n",
    "        layers = encoder.encoder.layer\n",
    "        for layer in layers[-unfreeze_last_n:]:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = True\n",
    "    elif hasattr(encoder, \"model\"):  # some Qwen variants wrap transformer under .model\n",
    "        if hasattr(encoder.model, \"layers\"):\n",
    "            layers = encoder.model.layers\n",
    "            for layer in layers[-unfreeze_last_n:]:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "    return encoder, tokenizer, hidden_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Learning\n",
    "In this section, I defined two functions, <code>training</code> and <code>testing</code>. The training function takes model, optimizer, dataset, and loss function. The model is an instance of the MLP class, optimizer is setted to Adam optimizer, the data is a batched data processd by the <code>DataLoader</code> and the criterion is a mean squared loss (MSE) function.\n",
    "\n",
    "The training function is responsible for the learning component of the model. The model takes a batch of essays and produce an output with similar batch size. The output is in the range of 0-1 as it is squashed using <code>sigmoid</code> activation function. By transforming the actual score into the range of 0-1, loss of the model is computed. For transformation of the actual score into 0-1, I employed <code>Min-Max Normalization</code>.\n",
    "$$\n",
    "    min-max-normalization = \\frac{score - min}{max  - min}\n",
    "$$\n",
    "where score is the essay score, min is the minimum score in the dataset and max is the maximum score in the dataset.\n",
    "\n",
    "The other function in this section is, testing function. This function is used to evaluate the performance of the model. To evaluate the model, the output values are transformed into the actual score format. The model is evaluated against minimizing the loss and the agreement of AES system with the human raters. For minimizing the loss, <code>MSELoss</code> from <code>PyTorch</code> is employed.\n",
    "$$\n",
    "    MSE = \\frac{1}{n}\\sum(output - scores)^2\n",
    "$$\n",
    "where the output is score predicted by the model and scores are actual score from the dataset. The predicted score in both training and testing has a different form. In training phase, the predict score is in the range of 0-1 whereas during testing it is transformed into the range of in the dataset (please check for the actual scores range of the essay in the <code>essay_set</code> variable).\n",
    "\n",
    "The other metrics used to measure the performance of the model is the raters' agreement. <code>scikit-learn</code> has an implementation of Cohen's kappa, <code>cohen_kappa_score</code>. This metrics measures the agreement level between raters. The score ranges from -1 to 1, where 1 indicates complete agreement, 0 agreement equivalent to chance and -1 complete disagreement.\n",
    "$$\n",
    "    k = 1 - \\frac{\\sum W_{i,j}O_{i,j}}{\\sum W_{i,j}E_{i,j}}\n",
    "$$\n",
    "where $O_{i,j}$ is a histogram matrix with the number of predicted labels that have a rating  of $i$ (actual) that received a predicted value $j$, $E_{i,j}$ is a histogram matrix of expected ratings calculated as the outer product between the actual rating's histogram vector of ratings and the predicted rating's histogram vector of ratings.\n",
    "$$\n",
    "    W_{i, j} = \\frac{(i-j)^2}{(R-1)^2}\n",
    "$$\n",
    "where $W_{i,j}$ is a weight matrix that is calculated based on the difference between actual and predicted values, and $R$ is the rating range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T06:13:02.577031Z",
     "iopub.status.busy": "2024-02-12T06:13:02.576558Z",
     "iopub.status.idle": "2024-02-12T06:13:02.590223Z",
     "shell.execute_reply": "2024-02-12T06:13:02.588799Z",
     "shell.execute_reply.started": "2024-02-12T06:13:02.576996Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EssayRegressor(nn.Module):\n",
    "    def __init__(self, encoder, hidden_size):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "        return self.mlp(cls_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset\n",
    "The ASAP-AES dataset is a popular dataset among AES researchers. The dataset can be downloaded from [Kaggle](https://www.kaggle.com/c/asap-aes). The dataset has 12976 entries and 28 columns (features). But for this project, I am only interested on 4 features, namely essay_id, essay_set, essay, and domain1_score.\n",
    " - essay_id is a unique id column for each entry\n",
    " - essay_set is an essay category. There are 8 essay sets, and each set represent different questions and different scoring range.\n",
    " - essay is a text response to the prompt given by student. This column is importtant feautre in the scoring process.\n",
    " - domain1_score is a score column. This field the summation of scores from two raters. In this project, the target value is this field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T06:13:07.320835Z",
     "iopub.status.busy": "2024-02-12T06:13:07.320368Z",
     "iopub.status.idle": "2024-02-12T06:13:07.731190Z",
     "shell.execute_reply": "2024-02-12T06:13:07.730021Z",
     "shell.execute_reply.started": "2024-02-12T06:13:07.320802Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score  \n",
       "0              8  \n",
       "1              9  \n",
       "2              7  \n",
       "3             10  \n",
       "4              8  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'training_set_rel3_cleaned.tsv'\n",
    "columns = ['essay_id', 'essay_set', 'essay', 'domain1_score']\n",
    "asap = pd.read_csv(file_path, sep='\\t', encoding='ISO-8859-1', usecols=columns)\n",
    "min_scores = [int(asap[asap[\"essay_set\"] == s][\"domain1_score\"].min()) for s in range(1, 9)]\n",
    "max_scores = [int(asap[asap[\"essay_set\"] == s][\"domain1_score\"].max()) for s in range(1, 9)]\n",
    "asap.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section contains an essay_set dictionary and two functions. The essay_set dictionary contains the score range of each prompts. For example, essay_set 1 has minimum value of 2 and a maximum value 12. These values are taken from the dataset description. \n",
    "\n",
    "The min_max_normalization and scaler functions are used to transform the scores from score range of the dataset into the range of 0-1 and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is splited into train, validation and test dataset. For training, 60% of the data is used, 20% of the data is used for validation and the rest is used for testing. <code>random_split</code> from PyTorch is used to spilt the data into the three settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T06:13:17.596340Z",
     "iopub.status.busy": "2024-02-12T06:13:17.595794Z",
     "iopub.status.idle": "2024-02-12T06:13:17.604150Z",
     "shell.execute_reply": "2024-02-12T06:13:17.602202Z",
     "shell.execute_reply.started": "2024-02-12T06:13:17.596302Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(prompt, test_size=0.2, val_size=0.2, seed=42):\n",
    "    df_prompt = asap[asap[\"essay_set\"] == prompt].copy()\n",
    "\n",
    "    train_val, test = train_test_split(df_prompt, test_size=test_size, random_state=seed)\n",
    "    train, val = train_test_split(train_val, test_size=val_size/(1-test_size), random_state=seed)\n",
    "\n",
    "    return train, val, test\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_dataloaders(train_df, val_df, test_df, tokenizer, prompt,\n",
    "                    batch_size=16, max_len=512):\n",
    "    \"\"\"\n",
    "    Build PyTorch dataloaders for a prompt (expects pandas DataFrames).\n",
    "    Scores are normalized with normalize_scores before being passed to the Dataset.\n",
    "    \"\"\"\n",
    "    # Normalize arrays (vectorized)\n",
    "    train_scores_norm = normalize_scores(train_df[\"domain1_score\"].values, prompt, min_scores, max_scores)\n",
    "    val_scores_norm   = normalize_scores(val_df[\"domain1_score\"].values,   prompt, min_scores, max_scores)\n",
    "    test_scores_norm  = normalize_scores(test_df[\"domain1_score\"].values,  prompt, min_scores, max_scores)\n",
    "\n",
    "    train_dataset = EssayDataset(train_df[\"essay\"].values, train_scores_norm, tokenizer, max_len=max_len)\n",
    "    val_dataset   = EssayDataset(val_df[\"essay\"].values,   val_scores_norm,   tokenizer, max_len=max_len)\n",
    "    test_dataset  = EssayDataset(test_df[\"essay\"].values,  test_scores_norm,  tokenizer, max_len=max_len)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
    "    test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_all_prompts(embedder,\n",
    "                      prompts=range(1,9),\n",
    "                      num_epochs=10,\n",
    "                      batch_size=16,\n",
    "                      lr=2e-5,\n",
    "                      patience=3,\n",
    "                      max_len=512,\n",
    "                      device=None):\n",
    "    \"\"\"\n",
    "    Loop over essay sets (prompts) and train separately for each.\n",
    "    Saves results to results.csv (train_and_evaluate does that).\n",
    "    Returns: pandas DataFrame summarizing returns from results.csv for the embedder run.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    summary = []\n",
    "\n",
    "    for prompt in prompts:\n",
    "        print(\"\\n\" + \"=\"*30)\n",
    "        print(f\" Training Essay Set {prompt} with embedder '{embedder}'\")\n",
    "        print(\"=\"*30)\n",
    "\n",
    "        # 1) get encoder & tokenizer for this embedder\n",
    "        encoder, tokenizer, hidden_size = get_encoder(embedder)\n",
    "\n",
    "        # 2) split dataset for this prompt\n",
    "        train_df, val_df, test_df = split_dataset(prompt, test_size=0.2, val_size=0.2, seed=42)\n",
    "\n",
    "        # 3) dataloaders (scores normalized inside)\n",
    "        train_loader, val_loader, test_loader = get_dataloaders(train_df, val_df, test_df,\n",
    "                                                                tokenizer, prompt,\n",
    "                                                                batch_size=batch_size, max_len=max_len)\n",
    "\n",
    "        # 4) model, optimizer, criterion\n",
    "        model = EssayRegressor(encoder, hidden_size)\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        # 5) train/evaluate for this prompt\n",
    "        train_losses, val_losses, val_qwks = train_and_evaluate(\n",
    "            model, train_loader, val_loader, test_loader,\n",
    "            optimizer, criterion, device, prompt, embedder,\n",
    "            num_epochs, patience\n",
    "        )\n",
    "\n",
    "        # 6) read the last row for this prompt from results.csv (optional) and append to summary\n",
    "        try:\n",
    "            df_results = pd.read_csv(\"results.csv\")\n",
    "            df_prompt = df_results[(df_results[\"embedder\"]==embedder) & (df_results[\"prompt\"]==prompt)]\n",
    "            if not df_prompt.empty:\n",
    "                row = df_prompt.iloc[-1].to_dict()\n",
    "            else:\n",
    "                row = {\"embedder\": embedder, \"prompt\": prompt, \"best_val_qwk\": None, \"best_val_mse\": None, \"test_qwk\": None, \"test_mse\": None}\n",
    "        except FileNotFoundError:\n",
    "            row = {\"embedder\": embedder, \"prompt\": prompt, \"best_val_qwk\": None, \"best_val_mse\": None, \"test_qwk\": None, \"test_mse\": None}\n",
    "\n",
    "        row[\"train_losses\"] = train_losses\n",
    "        row[\"val_losses\"] = val_losses\n",
    "        row[\"val_qwks\"] = val_qwks\n",
    "        summary.append(row)\n",
    "\n",
    "    summary_df = pd.DataFrame(summary)\n",
    "    return summary_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text representation\n",
    "The following section shows where the texts are transformed into numbers. Every text in the essay is represented by a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-12T06:13:23.818727Z",
     "iopub.status.busy": "2024-02-12T06:13:23.818248Z",
     "iopub.status.idle": "2024-02-12T06:13:23.826688Z",
     "shell.execute_reply": "2024-02-12T06:13:23.825377Z",
     "shell.execute_reply.started": "2024-02-12T06:13:23.818689Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, test_loader, \n",
    "                       optimizer, criterion, device, prompt, embedder, \n",
    "                       num_epochs=10, patience=3):\n",
    "\n",
    "    model = model.to(device)\n",
    "    best_val_qwk = -1.0\n",
    "    best_val_mse = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    train_losses, val_losses, val_qwks = [], [], []\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Training loop with progress bar\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Prompt {prompt} Epoch {epoch}\", leave=False)\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            scores = batch[\"score\"].to(device).unsqueeze(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, scores)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        val_qwk, val_mse = evaluate(model, val_loader, criterion, prompt, device)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(val_mse)\n",
    "        val_qwks.append(val_qwk)\n",
    "\n",
    "        print(f\"Prompt {prompt}, Epoch {epoch}: \"\n",
    "              f\"Train Loss={avg_train_loss:.4f}, \"\n",
    "              f\"Val QWK={val_qwk:.4f}, Val MSE={val_mse:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_qwk > best_val_qwk:\n",
    "            best_val_qwk = val_qwk\n",
    "            best_val_mse = val_mse\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"best_model_{embedder}_prompt{prompt}.pt\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    # Load best model before testing\n",
    "    model.load_state_dict(torch.load(f\"best_model_{embedder}_prompt{prompt}.pt\"))\n",
    "\n",
    "    # Final test evaluation\n",
    "    test_qwk, test_mse = evaluate(model, test_loader, criterion, prompt, device)\n",
    "    print(f\"✅ Prompt {prompt} | Test QWK={test_qwk:.4f}, Test MSE={test_mse:.4f}\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    results_df = pd.DataFrame([{\n",
    "        \"embedder\": embedder,\n",
    "        \"prompt\": prompt,\n",
    "        \"best_val_qwk\": best_val_qwk,\n",
    "        \"best_val_mse\": best_val_mse,\n",
    "        \"test_qwk\": test_qwk,\n",
    "        \"test_mse\": test_mse\n",
    "    }])\n",
    "\n",
    "    results_df.to_csv(\"results.csv\", mode=\"a\", header=not os.path.exists(\"results.csv\"), index=False)\n",
    "\n",
    "    return train_losses, val_losses, val_qwks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(model, loader, criterion, prompt, device):\n",
    "    \"\"\"\n",
    "    Evaluate model on loader.\n",
    "    Returns: (qwk_on_raw_scale, mse_on_raw_scale)\n",
    "    Note: loader should supply normalized scores (as used during training).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds_norm, all_labels_norm = [], []\n",
    "    total_loss = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            scores = batch[\"score\"].to(device).unsqueeze(1)    # normalized scores\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)        # normalized-pred outputs\n",
    "            loss = criterion(outputs, scores)\n",
    "            total_loss += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "            # Collect as numpy arrays\n",
    "            all_preds_norm.extend(outputs.squeeze(1).cpu().numpy())\n",
    "            all_labels_norm.extend(scores.squeeze(1).cpu().numpy())\n",
    "\n",
    "    if len(all_preds_norm) == 0:\n",
    "        return 0.0, 0.0  # safe fallback\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    all_preds_norm = np.array(all_preds_norm, dtype=float).flatten()\n",
    "    all_labels_norm = np.array(all_labels_norm, dtype=float).flatten()\n",
    "\n",
    "    # Denormalize both (raw score scale)\n",
    "    preds_raw = denormalize_scores(all_preds_norm, prompt, min_scores, max_scores)\n",
    "    labels_raw = denormalize_scores(all_labels_norm, prompt, min_scores, max_scores)\n",
    "\n",
    "    # Round predictions to nearest integer and clip to valid range for QWK\n",
    "    low, high = min_scores[prompt-1], max_scores[prompt-1]\n",
    "    preds_rounded = np.clip(np.rint(preds_raw), low, high).astype(int)\n",
    "    labels_int = labels_raw.astype(int)\n",
    "\n",
    "    # QWK (on integer original-score scale) and raw-scale MSE\n",
    "    try:\n",
    "        qwk = cohen_kappa_score(labels_int, preds_rounded, weights=\"quadratic\")\n",
    "    except Exception:\n",
    "        qwk = 0.0\n",
    "\n",
    "    mse_raw = mean_squared_error(labels_raw, preds_raw)\n",
    "\n",
    "    avg_loss = total_loss / n_batches if n_batches > 0 else 0.0\n",
    "    return qwk, mse_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Example: train Roberta per-prompt\n",
    "summary_bge= train_all_prompts(\n",
    "    embedder=\"bge\",\n",
    "    prompts=range(1,9),\n",
    "    num_epochs=10,\n",
    "    batch_size=8,\n",
    "    lr=2e-5,\n",
    "    patience=3,\n",
    "    max_len=256,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# See summary\n",
    "print(summary_bge[[\"embedder\",\"prompt\",\"best_val_qwk\",\"test_qwk\",\"test_mse\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " Training Essay Set 1 with embedder 'e5-base'\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1, Epoch 1: Train Loss=0.0285, Val QWK=0.5793, Val MSE=1.3398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1, Epoch 2: Train Loss=0.0170, Val QWK=0.6535, Val MSE=1.1099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1, Epoch 3: Train Loss=0.0134, Val QWK=0.6673, Val MSE=1.1773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1, Epoch 4: Train Loss=0.0107, Val QWK=0.7116, Val MSE=1.0656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1, Epoch 5: Train Loss=0.0102, Val QWK=0.7042, Val MSE=1.0644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1, Epoch 6: Train Loss=0.0090, Val QWK=0.6186, Val MSE=1.2026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1, Epoch 7: Train Loss=0.0074, Val QWK=0.7187, Val MSE=1.1444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1, Epoch 8: Train Loss=0.0073, Val QWK=0.6959, Val MSE=1.0340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1, Epoch 9: Train Loss=0.0065, Val QWK=0.6937, Val MSE=1.3473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1, Epoch 10: Train Loss=0.0057, Val QWK=0.6340, Val MSE=1.2697\n",
      "Early stopping triggered.\n",
      "✅ Prompt 1 | Test QWK=0.7244, Test MSE=1.0517\n",
      "\n",
      "==============================\n",
      " Training Essay Set 2 with embedder 'e5-base'\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 2, Epoch 1: Train Loss=0.0227, Val QWK=0.5741, Val MSE=0.3444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 2, Epoch 2: Train Loss=0.0143, Val QWK=0.5270, Val MSE=0.3733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 2, Epoch 3: Train Loss=0.0123, Val QWK=0.5810, Val MSE=0.3536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 2, Epoch 4: Train Loss=0.0096, Val QWK=0.6904, Val MSE=0.3281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 2, Epoch 5: Train Loss=0.0072, Val QWK=0.6621, Val MSE=0.3137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 2, Epoch 6: Train Loss=0.0071, Val QWK=0.6634, Val MSE=0.3513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 2, Epoch 7: Train Loss=0.0056, Val QWK=0.6689, Val MSE=0.3435\n",
      "Early stopping triggered.\n",
      "✅ Prompt 2 | Test QWK=0.4957, Test MSE=0.4048\n",
      "\n",
      "==============================\n",
      " Training Essay Set 3 with embedder 'e5-base'\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 3, Epoch 1: Train Loss=0.0544, Val QWK=0.6627, Val MSE=0.2926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 3, Epoch 2: Train Loss=0.0395, Val QWK=0.5639, Val MSE=0.4070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 3, Epoch 3: Train Loss=0.0346, Val QWK=0.6553, Val MSE=0.3253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 3, Epoch 4: Train Loss=0.0274, Val QWK=0.6605, Val MSE=0.3076\n",
      "Early stopping triggered.\n",
      "✅ Prompt 3 | Test QWK=0.6480, Test MSE=0.3062\n",
      "\n",
      "==============================\n",
      " Training Essay Set 4 with embedder 'e5-base'\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 4, Epoch 1: Train Loss=0.0516, Val QWK=0.7880, Val MSE=0.2482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 4, Epoch 2: Train Loss=0.0299, Val QWK=0.7554, Val MSE=0.2641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 4, Epoch 3: Train Loss=0.0244, Val QWK=0.8076, Val MSE=0.2266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 4, Epoch 4: Train Loss=0.0195, Val QWK=0.8159, Val MSE=0.2303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 4, Epoch 5: Train Loss=0.0149, Val QWK=0.8157, Val MSE=0.2828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 4, Epoch 6: Train Loss=0.0116, Val QWK=0.8318, Val MSE=0.2363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 4, Epoch 7: Train Loss=0.0083, Val QWK=0.7760, Val MSE=0.2846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 4, Epoch 8: Train Loss=0.0070, Val QWK=0.8154, Val MSE=0.2432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 4, Epoch 9: Train Loss=0.0065, Val QWK=0.8148, Val MSE=0.2593\n",
      "Early stopping triggered.\n",
      "✅ Prompt 4 | Test QWK=0.7906, Test MSE=0.2634\n",
      "\n",
      "==============================\n",
      " Training Essay Set 5 with embedder 'e5-base'\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 5, Epoch 1: Train Loss=0.0369, Val QWK=0.7993, Val MSE=0.3009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 5, Epoch 2: Train Loss=0.0204, Val QWK=0.7610, Val MSE=0.3057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 5, Epoch 3: Train Loss=0.0177, Val QWK=0.7617, Val MSE=0.2916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 5, Epoch 4: Train Loss=0.0140, Val QWK=0.7684, Val MSE=0.2937\n",
      "Early stopping triggered.\n",
      "✅ Prompt 5 | Test QWK=0.7870, Test MSE=0.2855\n",
      "\n",
      "==============================\n",
      " Training Essay Set 6 with embedder 'e5-base'\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 6, Epoch 1: Train Loss=0.0502, Val QWK=0.7287, Val MSE=0.3031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 6, Epoch 2: Train Loss=0.0231, Val QWK=0.8066, Val MSE=0.3074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 6, Epoch 3: Train Loss=0.0182, Val QWK=0.8203, Val MSE=0.3082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 6, Epoch 4: Train Loss=0.0167, Val QWK=0.7996, Val MSE=0.3876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 6, Epoch 5: Train Loss=0.0124, Val QWK=0.8416, Val MSE=0.2849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 6, Epoch 6: Train Loss=0.0106, Val QWK=0.8247, Val MSE=0.3016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 6, Epoch 7: Train Loss=0.0096, Val QWK=0.8258, Val MSE=0.2645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 6, Epoch 8: Train Loss=0.0083, Val QWK=0.8256, Val MSE=0.2729\n",
      "Early stopping triggered.\n",
      "✅ Prompt 6 | Test QWK=0.8192, Test MSE=0.2761\n",
      "\n",
      "==============================\n",
      " Training Essay Set 7 with embedder 'e5-base'\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 7, Epoch 1: Train Loss=0.0462, Val QWK=0.7263, Val MSE=9.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 7, Epoch 2: Train Loss=0.0207, Val QWK=0.7683, Val MSE=9.5226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 7, Epoch 3: Train Loss=0.0164, Val QWK=0.7560, Val MSE=8.1444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 7, Epoch 4: Train Loss=0.0147, Val QWK=0.7690, Val MSE=7.9610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 7, Epoch 5: Train Loss=0.0118, Val QWK=0.7716, Val MSE=7.3610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 7, Epoch 6: Train Loss=0.0106, Val QWK=0.7758, Val MSE=7.3055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 7, Epoch 7: Train Loss=0.0088, Val QWK=0.7246, Val MSE=9.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 7, Epoch 8: Train Loss=0.0075, Val QWK=0.7562, Val MSE=7.6330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 7, Epoch 9: Train Loss=0.0075, Val QWK=0.7607, Val MSE=8.3218\n",
      "Early stopping triggered.\n",
      "✅ Prompt 7 | Test QWK=0.8181, Test MSE=6.7164\n",
      "\n",
      "==============================\n",
      " Training Essay Set 8 with embedder 'e5-base'\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 8, Epoch 1: Train Loss=0.0399, Val QWK=0.5193, Val MSE=22.5325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 8, Epoch 2: Train Loss=0.0171, Val QWK=0.4966, Val MSE=20.9020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 8, Epoch 3: Train Loss=0.0134, Val QWK=0.3431, Val MSE=28.8511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 8, Epoch 4: Train Loss=0.0125, Val QWK=0.4934, Val MSE=30.7605\n",
      "Early stopping triggered.\n",
      "✅ Prompt 8 | Test QWK=0.4210, Test MSE=24.2088\n",
      "  embedder  prompt  best_val_qwk  test_qwk   test_mse\n",
      "0  e5-base       1      0.718743  0.724386   1.051668\n",
      "1  e5-base       2      0.690352  0.495698   0.404785\n",
      "2  e5-base       3      0.662742  0.648000   0.306180\n",
      "3  e5-base       4      0.831782  0.790569   0.263362\n",
      "4  e5-base       5      0.799291  0.786982   0.285463\n",
      "5  e5-base       6      0.841562  0.819156   0.276126\n",
      "6  e5-base       7      0.775820  0.818064   6.716422\n",
      "7  e5-base       8      0.519301  0.420953  24.208826\n"
     ]
    }
   ],
   "source": [
    "# choose device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Example: train Roberta per-prompt\n",
    "summary_e5base = train_all_prompts(\n",
    "    embedder=\"e5-base\",\n",
    "    prompts=range(1,9),\n",
    "    num_epochs=10,\n",
    "    batch_size=8,\n",
    "    lr=2e-5,\n",
    "    patience=3,\n",
    "    max_len=256,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# See summary\n",
    "print(summary_e5base[[\"embedder\",\"prompt\",\"best_val_qwk\",\"test_qwk\",\"test_mse\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " Training Essay Set 4 with embedder 'deberta'\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 4, Epoch 1: Train Loss=0.0727, Val QWK=0.7404, Val MSE=0.3121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 4, Epoch 2: Train Loss=0.0373, Val QWK=0.6695, Val MSE=0.3424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 4, Epoch 3: Train Loss=0.0291, Val QWK=0.8272, Val MSE=0.2366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 4, Epoch 4: Train Loss=0.0253, Val QWK=0.7656, Val MSE=0.2872\n",
      "✅ Prompt 4 | Test QWK=0.7880, Test MSE=0.2477\n",
      "\n",
      "==============================\n",
      " Training Essay Set 5 with embedder 'deberta'\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 5, Epoch 1: Train Loss=0.0667, Val QWK=0.7294, Val MSE=0.3695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 5, Epoch 2: Train Loss=0.0282, Val QWK=0.7740, Val MSE=0.3534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 5, Epoch 3: Train Loss=0.0216, Val QWK=0.7370, Val MSE=0.3852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 5, Epoch 4: Train Loss=0.0186, Val QWK=0.6862, Val MSE=0.4194\n",
      "✅ Prompt 5 | Test QWK=0.7501, Test MSE=0.3772\n",
      "\n",
      "==============================\n",
      " Training Essay Set 6 with embedder 'deberta'\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 6, Epoch 1: Train Loss=0.0638, Val QWK=0.7009, Val MSE=0.3838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 6, Epoch 2: Train Loss=0.0273, Val QWK=0.8051, Val MSE=0.2536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 6, Epoch 3: Train Loss=0.0227, Val QWK=0.8016, Val MSE=0.2508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 6, Epoch 4: Train Loss=0.0186, Val QWK=0.8184, Val MSE=0.2382\n",
      "✅ Prompt 6 | Test QWK=0.8185, Test MSE=0.2254\n",
      "\n",
      "==============================\n",
      " Training Essay Set 7 with embedder 'deberta'\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 7, Epoch 1: Train Loss=0.0594, Val QWK=0.5839, Val MSE=16.0890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 7, Epoch 2: Train Loss=0.0268, Val QWK=0.6670, Val MSE=11.5367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 7, Epoch 3: Train Loss=0.0189, Val QWK=0.7130, Val MSE=9.4810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 7, Epoch 4: Train Loss=0.0170, Val QWK=0.7436, Val MSE=8.5375\n",
      "✅ Prompt 7 | Test QWK=0.7587, Test MSE=8.6854\n",
      "\n",
      "==============================\n",
      " Training Essay Set 8 with embedder 'deberta'\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 8, Epoch 1: Train Loss=0.0429, Val QWK=0.4212, Val MSE=22.6998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 8, Epoch 2: Train Loss=0.0185, Val QWK=0.6646, Val MSE=17.6292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 8, Epoch 3: Train Loss=0.0134, Val QWK=0.6528, Val MSE=16.5421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 8, Epoch 4: Train Loss=0.0104, Val QWK=0.7447, Val MSE=14.1352\n",
      "✅ Prompt 8 | Test QWK=0.6711, Test MSE=14.5994\n",
      "  embedder  prompt  best_val_qwk  test_qwk   test_mse\n",
      "0  deberta       4      0.827238  0.787950   0.247699\n",
      "1  deberta       5      0.774021  0.750101   0.377177\n",
      "2  deberta       6      0.818390  0.818468   0.225355\n",
      "3  deberta       7      0.743593  0.758668   8.685395\n",
      "4  deberta       8      0.744720  0.671137  14.599413\n"
     ]
    }
   ],
   "source": [
    "# choose device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Example: train Roberta per-prompt\n",
    "summary_deberta = train_all_prompts(\n",
    "    embedder=\"deberta\",\n",
    "    prompts=range(4,9),\n",
    "    num_epochs=4,\n",
    "    batch_size=8,\n",
    "    lr=2e-5,\n",
    "    patience=3,\n",
    "    max_len=256,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# See summary\n",
    "print(summary_deberta[[\"embedder\",\"prompt\",\"best_val_qwk\",\"test_qwk\",\"test_mse\"]])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 29898,
     "sourceId": 2667,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
